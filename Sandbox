Avec pipeline pour séparer par locuteur : 

**code** 
=======================================================================================

!pip install pyannote.audio python-docx

from pyannote.audio import Pipeline
from google.colab import files
import torchaudio
import torch
import docx


uploaded = files.upload()
filename = list(uploaded.keys())[0]


pipeline = Pipeline.from_pretrained("pyannote/speaker-diarization",
                                    use_auth_token="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")


def split_audio(filename, segment_duration=10):
    waveform, sample_rate = torchaudio.load(filename)
    total_samples = waveform.shape[1]
    segment_samples = segment_duration * sample_rate
    segments = [waveform[:, i:i + segment_samples] for i in range(0, total_samples, segment_samples)]
    return segments, sample_rate

segments, sample_rate = split_audio(filename)


diarization_results = []
for segment in segments:
    segment_filename = "temp_segment.wav"
    torchaudio.save(segment_filename, segment, sample_rate)
    diarization_segment = pipeline(segment_filename)
    diarization_results.append(diarization_segment)


combined_diarization = None
for result in diarization_results:
    if combined_diarization is None:
        combined_diarization = result
    else:
        combined_diarization = combined_diarization.update(result)


!pip install git+https://github.com/openai/whisper.git
!sudo apt update && sudo apt install ffmpeg

import whisper

puissance = "turbo"  # @param ["base", "medium", "turbo", "large-v3"]
model = whisper.load_model(puissance)
result = model.transcribe(filename)


transcription = ""
for turn, _, speaker in combined_diarization.itertracks(yield_label=True):
    segment_start = turn.start
    segment_end = turn.end
    segment_text = [s["text"] for s in result["segments"] if segment_start <= s["start"] <= segment_end]

    # Remplacer les noms des locuteurs spécifiques par vos noms
    if speaker == "SPEAKER_01":
        speaker_name = "Votre Nom"
    elif speaker == "SPEAKER_02":
        speaker_name = "Nom Deuxième Locuteur"
    else:
        speaker_name = speaker

    transcription += f"\n{speaker_name}:\n"
    transcription += " ".join(segment_text) + "\n"


with open("transcription.txt", "w") as txt_file:
    txt_file.write(transcription)


doc = docx.Document()
doc.add_paragraph(transcription)
doc.save("transcription.docx")


files.download("transcription.txt")

=======================================================================================

le code passe bien mais le résultat est pas dingue (très nul même).
